◎ 월요일
    * 1층 클러스터 고치기
        현재 계속 1층 서버의 namenode가 계속 죽고, clockoffset 문제가 자꾸나는 현상이 일어나고 있다. 기본적으로 namenode가 죽었을때는 namenode를 껐다가 키면 대부분 잘 동작되었지만 어째서인지 껐다가 켜도 다운이 되는 현상이 계속 지속되었다. 이에 문제를 파악해보려 여러가지를 만져 보았으나 살리는데 실패했다. 짐작으로는 한대의 서버에서 4명이서 여러 작업을 동시에 진행하여서 서버에 무리가 가거나, 어느 누가 설정을 잘못 하였거나 namenode에 잘못 접근을하여 fsimage가 깨져버린 상황등 여러가지나 있기때문에 파악하기가 힘들었다. 한명이서 서버를 사용하면은 log를 보거나 history명령어를 통한 역추적이 수월하지만 여러명이서 사용하다보니 추적이 힘들어서 근본적인해결이 불가능 하였다. namenode가 죽었기 때문에 hdfs서비스를 이용할수 없고, 이에 여러 서비스를 이용할 수 없어서 서버를 다시 구축하기로 하였다. 이에 virtual machine들을 지우고 다시 처음부터 구축을 시작하였다. 다시 구축을 하고 과정들을 진행함에 따라 스냅샷을 찍어서 문제가 생길 시 백업을 할 수 있도록 만들었다.
◎ 화요일
    * Oozie
        월요일날 클러스터 초기화와 재 구축을 다 진행 하였지만 화요일에 다시 진행을 하려고 보니 clock offset이라는 경고를 보았다. 이는 ntp시간대가 맞지 않아서 나는 문제였다. 이를 해결하는 방법은 ntp를 재 설정해주면 보통 해결이 되었다. 그래서 ntp를 멈춘뒤에 pool로 시간대를 다운받고 적용시킨뒤 재시작을 하는 방식으로 ntp 시간대들을 동일하게 현재 시간으로 맞추었다. 그러나 시간이 지나면 또 호스트들이 clockoffset이라는 메세지를 보내면서 죽었다. 이런 경우는 처음이었다. 이렇게 자주 ntp시간대가 안맞는것은 네트워크의 문제인지 ntp자체의 문제인지는 구분 할 수가 없었다.
        클러스터를 지웠다가 다시 구축을 해보기도 하고 ntp시간대를 계속 맞춰주어도 봤지만 어느때는 맞춰졌다가도 다시 클러스터 신호등에 빨간불이 들어와서 확인해보면 다시 clock offset이 안맞다는 경고가 뜨기도 해서 이를 해결할 방법을 계속 찾아보았다. 이밨에도 namenode가 계속 죽는 현상이 지속되어서 다시한번 클러스터를 밀게 되었다.

◎ 수요일 ~ 금요일
    * admin 교육
        오늘부터 admin 교육이 시작되었다. 첫 주에 강의를 들었지만 실강과 느낌이 다를 거라 예상했다. 첫날의 강의 내용은 hadoop의 구성요소와 HDFS, YARN, SPARK의 기본적인 개념에 대해서 들었다. 이미 알고있는 내용들이긴 하지만 머리속으로 내용을 정리하기엔 최적이었다. 
            - 추가적으로 알게된 점
                1. 보안
                    하둡을 어느정도 이해 했다고 하면 보안에 대해서도 알아야 한다. 일반적으로 리눅스 자체에서도 보안을 제공하고 하둡내에서도 일정 수준까지는 제공하지만 데이터 자체의 중요도가 점점 늘어나게 되고 어느 데이터는 보안이 매우 중요하여서 보안에 대해 주의를 기울여야 한다. 예를 들면 개인정보를 들 수가 있는데 보안이 뚫리게 되면 회사가 막대한 손해를 입는 것 뿐만아니라 자칫하면 법적인 문제로 까지 번지게 된다. 이를 막기 위해선 보안을 좀더 강화할 필요가 있다. 기본적으로 제공되는 리눅스 보안은 SELINUX와 firewalld 기능이다. SELINUX는 iptable의 강화버전이라고 보면 되는데 기본적으로 리눅스는 임의 접근  통제 방식을 채택 하였지만  강제 접근 통제 방식을 구현해서 적용 시킨게 바로 SELINUX이다. 그리고 firewalld가 있는데 이도 마찬가지로 접근하는 포트들을 관리하여 강제로 접근하려는 포트들을 막아서 차단하는 방식이다. 이 방식만으로도 충분할것 같지만 좀더 보안을 강화하기 위해선 다른 것도 추가로 필요로 하다. 그 방법중 하나가 kerberos이다. kerberos는 HA로 구성을 시켜서 AD를 구축한다음 연결을 하게 되는데 AD는 active directory라고 사용자들의 권한을 저장하는 파일 구조 시스템이다. 여기에서 사용자들의 권한들을 설정하여 저장시켜 놓으면 cloudera에서 로그인 인증을 할때 이 값들을 읽어서 처리를 하여 인증도된 사용자의 권한 등급에 따라서 화면을 보여주게 된다. kerveros는 네트워크 보안 프로토콜로서 티켓을 기반으로 동작을 한다. 사용자가 인증을 요청하면 AD로 가서 인증을 비교한 뒤에 티켓을 발행하여 사용자에게 주는 방식이다. 이를 이용하면 기본적인 Cloudera의 보안에 더해져서 좀더 강화된 보안을 적용시킬 수 있게된다.
                2. 클러스터 구성
                    클러스터를 구성하는데에도 아무렇게나 막 구축하는게 아니라 기본적으로 설계를 하여야 한다. 회사가 돌릴 프로젝트의 규모를 파악한 다음 진행을 하여야 하는데 아무리 하둡의 장점이 분산저장, 분산처리라고는 하나 연결된 클러스터들의 컴퓨터의 성능이 기준치 이하이면은 문제가 생긴다. 하둡 구조상 클러스터의 호스트간의 통신들은 네트워크로 이루어 지기 때문에 네트워크 구성요소들의 스펙도 일정 수준 이상이 되어야 한다. 그리고 제일 중요한 것은 메모리이다. 메모리가 부족하게 되면 로그나 실행되는 작업의 내용을 저장할 곳이 없기 때문에 오류가 나게 된다. 대부분의 오류가 여기서 일어난다. 하둡의 처리는 소프트웨어적으로 일어난다고는 하나 저장은 하드웨어에 종속적일 수 밖에 없기 때문에 규모에 맞게 댓수를 정해야 한다. 그리고 메모리는 한번에 큰 저장소를 소규모로 하는것 보다는 중, 소 크기의 메모리를 여러개 구성하는 것이 효율적이다. 대 용량의 저장소가 한번에 죽어버리면 그안의 데이터를 복구하는데도 엄청난 비용이 들 뿐더러 손상이 된다면 그 데이터를 쓸 수 없게 되기 때문이다. 그렇기 때문에 작은 용량의 저장소를 쓴다면 그 손실 벙위가 작게되고 여러개를 갈아서 끼우면서 저장을 할 수 있기 때문에 효율적인 저장을 할 수 있게 된다. 
                3. 값 세부 조정
                    각 서비스들의 구성요소들은 세부 조정이 가능하다. 이 조정들은 CLI에서 기본적으로 가능하지만 이들 모두 Cloudera Manager에서 가능하다. CLI단에서 일정 부분들을 조정하려고 하면 그 구성을 공유하는 모든 파일들을 찾아가서 고쳐 주어야 하는 번거로움이 있다. 그렇지 많다면 그 조정값들의 차이 때문에 잘 돌아가지 않을 수가 있다. 그렇게 사용자가 직접 값들을 만지게 되면 오류가 날 수 있기 때문에 이를 잡는데에도 시간이 많이 걸리게 된다. 이에 CM에서는 간단하게 조정을 할 수가 있다. 구성페이지에 들어가서 값을을 조정할 수 있는데 CLI창에서 이를 바꾸려고하면 각각의 xml파일에 직접 하나하나 들어가서 바꾸어 주어야 한다. 이를 잘못하면 또 클러스터가 고장이 나는 경우가 있기 때문에 신중하게 값들을 바꾸어 주어야 한다. CM에서는 값을 조정하면 필요한 부분의 xml들에게 모두 자동으로 적용을 시켜주기 때문에 번거로운 작업을 거치지 않고 간단하게 세부 값들을 조정할 수가 있다.
                4. HA 구성
                    HA는 High Avility의 약자로 서버를 이중화 시켜서 고 가용성을 높이는 방법을 지칭한다. 단일 노드일때는 name node가 죽어버리면 죽어 있는동안 서비스를 진행 할 수가 없다. 그렇기 때문에 fail over를 위하여 name node 서버를 두개를 만들어서 하나는 대기 상태로 놓았다가 메인 서버가 죽게되면 이어서 바로 작동이 되어서 서비스 제공에 차질이 없도록 하는 방법이다. 단일 노드 구성에서는 name node와  secondary name node가 있었는데 secondary namenode는 failover가 되질 않고 recovery기능 만을 제공하였다.
    
    * Lab 실습과정
        실습 과정은 미리 구축되어있는 클러스터에서 진행하였다. HDFS에 YARN과 SPARK, IMPALA를 이용하여 데이터를 핸들링하는 실습을 진행하였다. 
        여기서 한가지 궁금한 점이 생겼는데, 이론상으로는 IMPALA가 가장 빠르고 SPARK가 그다음, YARN MapReduce가 그 다음으로 빨라야 하는데 IMPALA은 확실히 자체 IMPALA DEMON에서돌기 때문에 빠르다는게 보였는데 SPARK보다는 YARN으로 돌리는게 오히려 더 빠른 결과가 나왔다. 이는 큰 데이터가 아니라 몇 GB밖에 안되는 데이터라서 그러는지, 아니면 다른 이유가 있는지는 확인을 하지 못하였다.